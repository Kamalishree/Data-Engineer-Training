{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lk-qyGHETFd1",
        "outputId": "442414f7-a76a-429b-a601-18b6eb5a7c95"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Create required CSV files (Week 1 data)\n",
        "import pandas as pd\n",
        "\n",
        "# Create Dataset folder\n",
        "import os\n",
        "os.makedirs(\"WEEK_3/Dataset\", exist_ok=True)\n",
        "os.makedirs(\"WEEK_3/Deliverables\", exist_ok=True)\n",
        "\n",
        "# customers.csv\n",
        "customers = pd.DataFrame({\n",
        "    \"customer_id\": [1, 2, 3, 4, 5],\n",
        "    \"customer_name\": [\"Asha Patel\", \"Rohan Sharma\", \"Neha Reddy\", \"Arjun Mehta\", \"Isha Kapoor\"],\n",
        "    \"email\": [\n",
        "        \"asha.patel@example.com\",\n",
        "        \"rohan.sharma@example.com\",\n",
        "        \"neha.reddy@example.com\",\n",
        "        \"arjun.mehta@example.com\",\n",
        "        \"isha.kapoor@example.com\"\n",
        "    ],\n",
        "    \"region\": [\"South\", \"North\", \"West\", \"East\", \"South\"]\n",
        "})\n",
        "customers.to_csv(\"WEEK_3/Dataset/customers.csv\", index=False)\n",
        "\n",
        "# orders.csv\n",
        "orders = pd.DataFrame({\n",
        "    \"order_id\": [1, 2, 3, 4, 5],\n",
        "    \"customer_id\": [1, 2, 3, 4, 5],\n",
        "    \"order_date\": [\"2025-07-10\", \"2025-07-11\", \"2025-07-12\", \"2025-07-13\", \"2025-07-14\"],\n",
        "    \"delivery_date\": [\"2025-07-15\", \"2025-07-20\", \"2025-07-17\", \"\", \"2025-07-22\"],\n",
        "    \"total_amount\": [1500, 2300, 1800, 2100, 2500]\n",
        "})\n",
        "orders.to_csv(\"WEEK_3/Dataset/orders.csv\", index=False)\n",
        "\n",
        "# delivery_status.csv\n",
        "delivery = pd.DataFrame({\n",
        "    \"delivery_id\": [201, 202, 203, 204, 205],\n",
        "    \"order_id\": [1, 2, 3, 4, 5],\n",
        "    \"status\": [\"Delivered\", \"Delayed\", \"Delivered\", \"In Transit\", \"Delayed\"],\n",
        "    \"updated_at\": [\"2025-07-15\", \"2025-07-20\", \"2025-07-17\", \"2025-07-18\", \"2025-07-22\"],\n",
        "    \"carrier\": [\"BlueDart\", \"Delhivery\", \"FedEx\", \"Ecom Express\", \"XpressBees\"],\n",
        "    \"remarks\": [\n",
        "        \"Delivered on time\",\n",
        "        \"Delayed due to rain\",\n",
        "        \"Delivered successfully\",\n",
        "        \"Still in transit\",\n",
        "        \"Customer not available\"\n",
        "    ]\n",
        "})\n",
        "delivery.to_csv(\"WEEK_3/Dataset/delivery_status.csv\", index=False)\n",
        "\n",
        "print(\"All Week 1 CSVs created under WEEK_3/Dataset\")\n",
        "\n",
        "# Step 2: PySpark Setup\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, when\n",
        "\n",
        "spark = SparkSession.builder.appName(\"Customer_Order_Analysis\").getOrCreate()\n",
        "\n",
        "# Step 3: Load CSVs using Spark\n",
        "customers_df = spark.read.option(\"header\", True).csv(\"WEEK_3/Dataset/customers.csv\")\n",
        "orders_df = spark.read.option(\"header\", True).csv(\"WEEK_3/Dataset/orders.csv\")\n",
        "delivery_status_df = spark.read.option(\"header\", True).csv(\"WEEK_3/Dataset/delivery_status.csv\")\n",
        "\n",
        "# Step 4: Convert types and calculate delay\n",
        "orders_df = orders_df.withColumn(\"order_id\", col(\"order_id\").cast(\"int\")) \\\n",
        "                     .withColumn(\"customer_id\", col(\"customer_id\").cast(\"int\")) \\\n",
        "                     .withColumn(\"order_date\", col(\"order_date\").cast(\"timestamp\")) \\\n",
        "                     .withColumn(\"delivery_date\", col(\"delivery_date\").cast(\"timestamp\")) \\\n",
        "                     .withColumn(\"delay_days\",\n",
        "                                 when(col(\"delivery_date\").isNotNull(),\n",
        "                                      (col(\"delivery_date\").cast(\"long\") - col(\"order_date\").cast(\"long\")) / 86400\n",
        "                                 ).otherwise(0)) \\\n",
        "                     .withColumn(\"is_delayed\", when(col(\"delay_days\") > 3, 1).otherwise(0))\n",
        "\n",
        "customers_df = customers_df.withColumn(\"customer_id\", col(\"customer_id\").cast(\"int\"))\n",
        "\n",
        "# Step 5: Join customers and orders\n",
        "joined_df = orders_df.join(customers_df, on=\"customer_id\", how=\"inner\")\n",
        "\n",
        "# Step 6: Group by region and count delayed orders\n",
        "delay_summary = joined_df.groupBy(\"region\").sum(\"is_delayed\") \\\n",
        "                         .withColumnRenamed(\"sum(is_delayed)\", \"delayed_orders\")\n",
        "\n",
        "# Step 7: Save final result to Deliverables folder\n",
        "delay_summary.coalesce(1).write.mode(\"overwrite\").option(\"header\", True).csv(\"WEEK_3/Deliverables/delayed_orders_by_region\")\n",
        "\n",
        "print(\"\\nWeek 3 output saved as WEEK_3/Deliverables/delayed_orders_by_region.csv\")\n",
        "delay_summary.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rK0oRiOuTPGp",
        "outputId": "b9162ff0-4488-4b55-f592-323672bf643f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All Week 1 CSVs created under WEEK_3/Dataset\n",
            "\n",
            "Week 3 output saved as WEEK_3/Deliverables/delayed_orders_by_region.csv\n",
            "+------+--------------+\n",
            "|region|delayed_orders|\n",
            "+------+--------------+\n",
            "| South|             2|\n",
            "|  East|             0|\n",
            "|  West|             1|\n",
            "| North|             1|\n",
            "+------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import glob\n",
        "\n",
        "# Get the actual CSV file path created by Spark\n",
        "output_folder = \"WEEK_3/Deliverables/delayed_orders_by_region\"\n",
        "part_file = glob.glob(f\"{output_folder}/part-*.csv\")[0]  # first part file\n",
        "final_csv = \"WEEK_3/Deliverables/delayed_orders_by_region.csv\"\n",
        "\n",
        "# Move and rename\n",
        "shutil.move(part_file, final_csv)\n",
        "print(f\" Final CSV ready: {final_csv}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "ytK0U2FoUJxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(final_csv)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "780xwMXlULAV",
        "outputId": "338f32e3-9ade-4e87-b5ab-5f2db3d629b0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f177e073-46bb-4780-868e-4307ba085b71\", \"delayed_orders_by_region.csv\", 52)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}