{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5XUZPKktajx6"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, expr, month, year, avg, max, when, countDistinct, sum as _sum, rank\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "# Create SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"ProductOrdersAnalytics\") \\\n",
        "    .config(\"spark.sql.warehouse.dir\", \"/tmp/spark-warehouse\") \\\n",
        "    .enableHiveSupport() \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Sample order data\n",
        "order_data = [\n",
        "    (101, \"Alice\", \"Laptop\", \"Electronics\", 2, 50000, \"2023-01-05\"),\n",
        "    (102, \"Bob\", \"Jeans\", \"Clothing\", 1, 2000, \"2023-01-10\"),\n",
        "    (103, \"Charlie\", \"Chair\", \"Furniture\", 3, 3000, \"2023-02-12\"),\n",
        "    (104, \"David\", \"Smartphone\", \"Electronics\", 1, 30000, \"2023-01-20\"),\n",
        "    (105, \"Eve\", \"Bookshelf\", \"Furniture\", 2, 8000, \"2023-03-18\"),\n",
        "    (106, \"Frank\", \"Shirt\", \"Clothing\", 5, 1500, \"2023-02-22\"),\n",
        "    (107, \"Grace\", \"Tablet\", \"Electronics\", 2, 25000, \"2023-01-25\"),\n",
        "    (108, \"Heidi\", \"Novel\", \"Books\", 4, 500, \"2023-03-03\"),\n",
        "    (109, \"Ivan\", \"Textbook\", \"Books\", 1, 1200, \"2023-03-05\"),\n",
        "    (110, \"Judy\", \"Sofa\", \"Furniture\", 1, 20000, \"2023-01-15\"),\n",
        "    (111, \"Mallory\", \"Dress\", \"Clothing\", 2, 2500, \"2023-03-20\"),\n",
        "    (112, \"Niaj\", \"Notebook\", \"Books\", 3, 800, \"2023-02-11\"),\n",
        "]\n",
        "\n",
        "columns = [\"OrderID\", \"CustomerName\", \"Product\", \"Category\", \"Quantity\", \"UnitPrice\", \"OrderDate\"]\n",
        "df = spark.createDataFrame(order_data, columns)\n",
        "\n",
        "# Create views\n",
        "df.createOrReplaceTempView(\"orders_local\")\n",
        "df.createOrReplaceGlobalTempView(\"orders_global\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Electronics orders with Quantity >= 2\n",
        "spark.sql(\"\"\"\n",
        "    SELECT * FROM orders_local\n",
        "    WHERE Category = 'Electronics' AND Quantity >= 2\n",
        "\"\"\").show()\n",
        "\n",
        "# 2. Add TotalAmount column (Quantity * UnitPrice)\n",
        "spark.sql(\"\"\"\n",
        "    SELECT *, Quantity * UnitPrice AS TotalAmount\n",
        "    FROM orders_local\n",
        "\"\"\").show()\n",
        "\n",
        "# 3. Total number of orders per Category\n",
        "spark.sql(\"\"\"\n",
        "    SELECT Category, COUNT(*) AS OrderCount\n",
        "    FROM orders_local\n",
        "    GROUP BY Category\n",
        "\"\"\").show()\n",
        "\n",
        "# 4. Orders placed in January 2023\n",
        "spark.sql(\"\"\"\n",
        "    SELECT * FROM orders_local\n",
        "    WHERE OrderDate LIKE '2023-01-%'\n",
        "\"\"\").show()\n",
        "\n",
        "# 5. Average UnitPrice per Category\n",
        "spark.sql(\"\"\"\n",
        "    SELECT Category, AVG(UnitPrice) AS AvgPrice\n",
        "    FROM orders_local\n",
        "    GROUP BY Category\n",
        "\"\"\").show()\n",
        "\n",
        "# 6. Order with the highest total amount\n",
        "spark.sql(\"\"\"\n",
        "    SELECT *, Quantity * UnitPrice AS TotalAmount\n",
        "    FROM orders_local\n",
        "    ORDER BY TotalAmount DESC\n",
        "    LIMIT 1\n",
        "\"\"\").show()\n",
        "\n",
        "# 7. Drop local view and try querying again\n",
        "spark.catalog.dropTempView(\"orders_local\")\n",
        "try:\n",
        "    spark.sql(\"SELECT * FROM orders_local\").show()\n",
        "except Exception as e:\n",
        "    print(\"Error after dropping local view:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nn16xQeUa0gL",
        "outputId": "7b0dfd4b-e3a9-44b0-c83e-0a3cb3fc4c41"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------+-------+-----------+--------+---------+----------+\n",
            "|OrderID|CustomerName|Product|   Category|Quantity|UnitPrice| OrderDate|\n",
            "+-------+------------+-------+-----------+--------+---------+----------+\n",
            "|    101|       Alice| Laptop|Electronics|       2|    50000|2023-01-05|\n",
            "|    107|       Grace| Tablet|Electronics|       2|    25000|2023-01-25|\n",
            "+-------+------------+-------+-----------+--------+---------+----------+\n",
            "\n",
            "+-------+------------+----------+-----------+--------+---------+----------+-----------+\n",
            "|OrderID|CustomerName|   Product|   Category|Quantity|UnitPrice| OrderDate|TotalAmount|\n",
            "+-------+------------+----------+-----------+--------+---------+----------+-----------+\n",
            "|    101|       Alice|    Laptop|Electronics|       2|    50000|2023-01-05|     100000|\n",
            "|    102|         Bob|     Jeans|   Clothing|       1|     2000|2023-01-10|       2000|\n",
            "|    103|     Charlie|     Chair|  Furniture|       3|     3000|2023-02-12|       9000|\n",
            "|    104|       David|Smartphone|Electronics|       1|    30000|2023-01-20|      30000|\n",
            "|    105|         Eve| Bookshelf|  Furniture|       2|     8000|2023-03-18|      16000|\n",
            "|    106|       Frank|     Shirt|   Clothing|       5|     1500|2023-02-22|       7500|\n",
            "|    107|       Grace|    Tablet|Electronics|       2|    25000|2023-01-25|      50000|\n",
            "|    108|       Heidi|     Novel|      Books|       4|      500|2023-03-03|       2000|\n",
            "|    109|        Ivan|  Textbook|      Books|       1|     1200|2023-03-05|       1200|\n",
            "|    110|        Judy|      Sofa|  Furniture|       1|    20000|2023-01-15|      20000|\n",
            "|    111|     Mallory|     Dress|   Clothing|       2|     2500|2023-03-20|       5000|\n",
            "|    112|        Niaj|  Notebook|      Books|       3|      800|2023-02-11|       2400|\n",
            "+-------+------------+----------+-----------+--------+---------+----------+-----------+\n",
            "\n",
            "+-----------+----------+\n",
            "|   Category|OrderCount|\n",
            "+-----------+----------+\n",
            "|Electronics|         3|\n",
            "|   Clothing|         3|\n",
            "|  Furniture|         3|\n",
            "|      Books|         3|\n",
            "+-----------+----------+\n",
            "\n",
            "+-------+------------+----------+-----------+--------+---------+----------+\n",
            "|OrderID|CustomerName|   Product|   Category|Quantity|UnitPrice| OrderDate|\n",
            "+-------+------------+----------+-----------+--------+---------+----------+\n",
            "|    101|       Alice|    Laptop|Electronics|       2|    50000|2023-01-05|\n",
            "|    102|         Bob|     Jeans|   Clothing|       1|     2000|2023-01-10|\n",
            "|    104|       David|Smartphone|Electronics|       1|    30000|2023-01-20|\n",
            "|    107|       Grace|    Tablet|Electronics|       2|    25000|2023-01-25|\n",
            "|    110|        Judy|      Sofa|  Furniture|       1|    20000|2023-01-15|\n",
            "+-------+------------+----------+-----------+--------+---------+----------+\n",
            "\n",
            "+-----------+------------------+\n",
            "|   Category|          AvgPrice|\n",
            "+-----------+------------------+\n",
            "|Electronics|           35000.0|\n",
            "|   Clothing|            2000.0|\n",
            "|  Furniture|10333.333333333334|\n",
            "|      Books| 833.3333333333334|\n",
            "+-----------+------------------+\n",
            "\n",
            "+-------+------------+-------+-----------+--------+---------+----------+-----------+\n",
            "|OrderID|CustomerName|Product|   Category|Quantity|UnitPrice| OrderDate|TotalAmount|\n",
            "+-------+------------+-------+-----------+--------+---------+----------+-----------+\n",
            "|    101|       Alice| Laptop|Electronics|       2|    50000|2023-01-05|     100000|\n",
            "+-------+------------+-------+-----------+--------+---------+----------+-----------+\n",
            "\n",
            "Error after dropping local view: [TABLE_OR_VIEW_NOT_FOUND] The table or view `orders_local` cannot be found. Verify the spelling and correctness of the schema and catalog.\n",
            "If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\n",
            "To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 1 pos 14;\n",
            "'Project [*]\n",
            "+- 'UnresolvedRelation [orders_local], [], false\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Furniture orders with TotalAmount > 10,000\n",
        "spark.sql(\"\"\"\n",
        "    SELECT *, Quantity * UnitPrice AS TotalAmount\n",
        "    FROM global_temp.orders_global\n",
        "    WHERE Category = 'Furniture' AND (Quantity * UnitPrice) > 10000\n",
        "\"\"\").show()\n",
        "\n",
        "# 2. Add DiscountFlag column\n",
        "spark.sql(\"\"\"\n",
        "    SELECT *,\n",
        "        CASE WHEN Quantity > 3 THEN 'Yes' ELSE 'No' END AS DiscountFlag\n",
        "    FROM global_temp.orders_global\n",
        "\"\"\").show()\n",
        "\n",
        "# 3. Customers who ordered more than 1 product type\n",
        "spark.sql(\"\"\"\n",
        "    SELECT CustomerName\n",
        "    FROM global_temp.orders_global\n",
        "    GROUP BY CustomerName\n",
        "    HAVING COUNT(DISTINCT Category) > 1\n",
        "\"\"\").show()\n",
        "\n",
        "# 4. Count number of orders per month\n",
        "spark.sql(\"\"\"\n",
        "    SELECT\n",
        "        CONCAT(YEAR(TO_DATE(OrderDate)), '-', LPAD(MONTH(TO_DATE(OrderDate)), 2, '0')) AS YearMonth,\n",
        "        COUNT(*) AS OrderCount\n",
        "    FROM global_temp.orders_global\n",
        "    GROUP BY YearMonth\n",
        "    ORDER BY YearMonth\n",
        "\"\"\").show()\n",
        "\n",
        "# 5. Rank all products by total quantity sold\n",
        "ranked_df = df.groupBy(\"Product\") \\\n",
        "    .agg(_sum(\"Quantity\").alias(\"TotalQuantity\")) \\\n",
        "    .withColumn(\"Rank\", rank().over(Window.orderBy(col(\"TotalQuantity\").desc())))\n",
        "\n",
        "ranked_df.show()\n",
        "\n",
        "# 6. Query global view using new SparkSession\n",
        "new_spark = SparkSession.builder.appName(\"NewSession\").getOrCreate()\n",
        "new_spark.sql(\"SELECT * FROM global_temp.orders_global WHERE Category = 'Books'\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYl7QjmYa3W2",
        "outputId": "10f5cfcb-c813-4488-8288-e04ed455421b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------+---------+---------+--------+---------+----------+-----------+\n",
            "|OrderID|CustomerName|  Product| Category|Quantity|UnitPrice| OrderDate|TotalAmount|\n",
            "+-------+------------+---------+---------+--------+---------+----------+-----------+\n",
            "|    105|         Eve|Bookshelf|Furniture|       2|     8000|2023-03-18|      16000|\n",
            "|    110|        Judy|     Sofa|Furniture|       1|    20000|2023-01-15|      20000|\n",
            "+-------+------------+---------+---------+--------+---------+----------+-----------+\n",
            "\n",
            "+-------+------------+----------+-----------+--------+---------+----------+------------+\n",
            "|OrderID|CustomerName|   Product|   Category|Quantity|UnitPrice| OrderDate|DiscountFlag|\n",
            "+-------+------------+----------+-----------+--------+---------+----------+------------+\n",
            "|    101|       Alice|    Laptop|Electronics|       2|    50000|2023-01-05|          No|\n",
            "|    102|         Bob|     Jeans|   Clothing|       1|     2000|2023-01-10|          No|\n",
            "|    103|     Charlie|     Chair|  Furniture|       3|     3000|2023-02-12|          No|\n",
            "|    104|       David|Smartphone|Electronics|       1|    30000|2023-01-20|          No|\n",
            "|    105|         Eve| Bookshelf|  Furniture|       2|     8000|2023-03-18|          No|\n",
            "|    106|       Frank|     Shirt|   Clothing|       5|     1500|2023-02-22|         Yes|\n",
            "|    107|       Grace|    Tablet|Electronics|       2|    25000|2023-01-25|          No|\n",
            "|    108|       Heidi|     Novel|      Books|       4|      500|2023-03-03|         Yes|\n",
            "|    109|        Ivan|  Textbook|      Books|       1|     1200|2023-03-05|          No|\n",
            "|    110|        Judy|      Sofa|  Furniture|       1|    20000|2023-01-15|          No|\n",
            "|    111|     Mallory|     Dress|   Clothing|       2|     2500|2023-03-20|          No|\n",
            "|    112|        Niaj|  Notebook|      Books|       3|      800|2023-02-11|          No|\n",
            "+-------+------------+----------+-----------+--------+---------+----------+------------+\n",
            "\n",
            "+------------+\n",
            "|CustomerName|\n",
            "+------------+\n",
            "+------------+\n",
            "\n",
            "+---------+----------+\n",
            "|YearMonth|OrderCount|\n",
            "+---------+----------+\n",
            "|  2023-01|         5|\n",
            "|  2023-02|         3|\n",
            "|  2023-03|         4|\n",
            "+---------+----------+\n",
            "\n",
            "+----------+-------------+----+\n",
            "|   Product|TotalQuantity|Rank|\n",
            "+----------+-------------+----+\n",
            "|     Shirt|            5|   1|\n",
            "|     Novel|            4|   2|\n",
            "|     Chair|            3|   3|\n",
            "|  Notebook|            3|   3|\n",
            "|    Laptop|            2|   5|\n",
            "| Bookshelf|            2|   5|\n",
            "|     Dress|            2|   5|\n",
            "|    Tablet|            2|   5|\n",
            "|Smartphone|            1|   9|\n",
            "|     Jeans|            1|   9|\n",
            "|  Textbook|            1|   9|\n",
            "|      Sofa|            1|   9|\n",
            "+----------+-------------+----+\n",
            "\n",
            "+-------+------------+--------+--------+--------+---------+----------+\n",
            "|OrderID|CustomerName| Product|Category|Quantity|UnitPrice| OrderDate|\n",
            "+-------+------------+--------+--------+--------+---------+----------+\n",
            "|    108|       Heidi|   Novel|   Books|       4|      500|2023-03-03|\n",
            "|    109|        Ivan|Textbook|   Books|       1|     1200|2023-03-05|\n",
            "|    112|        Niaj|Notebook|   Books|       3|      800|2023-02-11|\n",
            "+-------+------------+--------+--------+--------+---------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Save \"Books\" only as new global temp view\n",
        "books_df = df.filter(col(\"Category\") == \"Books\")\n",
        "books_df.createOrReplaceGlobalTempView(\"books_orders\")\n",
        "\n",
        "# 2. Most purchased product per category\n",
        "windowSpec = Window.partitionBy(\"Category\").orderBy(col(\"TotalQty\").desc())\n",
        "\n",
        "df.groupBy(\"Category\", \"Product\") \\\n",
        "  .agg(_sum(\"Quantity\").alias(\"TotalQty\")) \\\n",
        "  .withColumn(\"Rank\", rank().over(windowSpec)) \\\n",
        "  .filter(col(\"Rank\") == 1) \\\n",
        "  .select(\"Category\", \"Product\", \"TotalQty\") \\\n",
        "  .show()\n",
        "\n",
        "# 3. View that excludes all Clothing orders → \"filtered_orders\"\n",
        "df.filter(col(\"Category\") != \"Clothing\") \\\n",
        "  .createOrReplaceTempView(\"filtered_orders\")\n",
        "\n",
        "# To verify:\n",
        "spark.sql(\"SELECT DISTINCT Category FROM filtered_orders\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzEp98bZa8ED",
        "outputId": "0cb2d1b0-465c-4644-cb10-62f56cd0ea42"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+--------+\n",
            "|   Category|Product|TotalQty|\n",
            "+-----------+-------+--------+\n",
            "|      Books|  Novel|       4|\n",
            "|   Clothing|  Shirt|       5|\n",
            "|Electronics| Laptop|       2|\n",
            "|Electronics| Tablet|       2|\n",
            "|  Furniture|  Chair|       3|\n",
            "+-----------+-------+--------+\n",
            "\n",
            "+-----------+\n",
            "|   Category|\n",
            "+-----------+\n",
            "|Electronics|\n",
            "|  Furniture|\n",
            "|      Books|\n",
            "+-----------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}