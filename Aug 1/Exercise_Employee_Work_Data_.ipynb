{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HCMZfEjn-rPp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fc51827-40f5-40dd-c663-a5404adc1526"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+-----------+---------------+------+------------+\n",
            "|EmpID|Name |Department |Project        |Salary|HoursPerWeek|\n",
            "+-----+-----+-----------+---------------+------+------------+\n",
            "|101  |Ravi |Engineering|AI Engine      |95000 |42          |\n",
            "|102  |Sneha|Engineering|Data Platform  |87000 |45          |\n",
            "|103  |Kabir|Marketing  |Product Launch |65000 |40          |\n",
            "|104  |Anita|Sales      |Client Outreach|70000 |38          |\n",
            "|105  |Divya|Engineering|AI Engine      |99000 |48          |\n",
            "|106  |Amit |Marketing  |Social Media   |62000 |35          |\n",
            "|107  |Priya|HR         |Policy Revamp  |58000 |37          |\n",
            "|108  |Manav|Sales      |Lead Gen       |73000 |41          |\n",
            "|109  |Neha |Engineering|Security Suite |91000 |46          |\n",
            "|110  |Farah|HR         |Onboarding     |60000 |36          |\n",
            "+-----+-----+-----------+---------------+------+------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession, Row\n",
        "\n",
        "# Step 1: Start Spark Session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"EmployeeWorkData\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Step 2: Prepare Sample Employee Data\n",
        "data = [\n",
        "    Row(EmpID=101, Name=\"Ravi\", Department=\"Engineering\", Project=\"AI Engine\", Salary=95000, HoursPerWeek=42),\n",
        "    Row(EmpID=102, Name=\"Sneha\", Department=\"Engineering\", Project=\"Data Platform\", Salary=87000, HoursPerWeek=45),\n",
        "    Row(EmpID=103, Name=\"Kabir\", Department=\"Marketing\", Project=\"Product Launch\", Salary=65000, HoursPerWeek=40),\n",
        "    Row(EmpID=104, Name=\"Anita\", Department=\"Sales\", Project=\"Client Outreach\", Salary=70000, HoursPerWeek=38),\n",
        "    Row(EmpID=105, Name=\"Divya\", Department=\"Engineering\", Project=\"AI Engine\", Salary=99000, HoursPerWeek=48),\n",
        "    Row(EmpID=106, Name=\"Amit\", Department=\"Marketing\", Project=\"Social Media\", Salary=62000, HoursPerWeek=35),\n",
        "    Row(EmpID=107, Name=\"Priya\", Department=\"HR\", Project=\"Policy Revamp\", Salary=58000, HoursPerWeek=37),\n",
        "    Row(EmpID=108, Name=\"Manav\", Department=\"Sales\", Project=\"Lead Gen\", Salary=73000, HoursPerWeek=41),\n",
        "    Row(EmpID=109, Name=\"Neha\", Department=\"Engineering\", Project=\"Security Suite\", Salary=91000, HoursPerWeek=46),\n",
        "    Row(EmpID=110, Name=\"Farah\", Department=\"HR\", Project=\"Onboarding\", Salary=60000, HoursPerWeek=36)\n",
        "]\n",
        "\n",
        "# Step 3: Create DataFrame\n",
        "df = spark.createDataFrame(data)\n",
        "\n",
        "# Show DataFrame (without truncation)\n",
        "df.show(truncate=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Local Temporary View\n",
        "df.createOrReplaceTempView(\"employees_local\")\n",
        "\n",
        "# Create a Global Temporary View\n",
        "df.createOrReplaceGlobalTempView(\"employees_global\")\n"
      ],
      "metadata": {
        "id": "nk60vCJIDEGJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"SELECT * FROM employees_local WHERE Department = 'Engineering'\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENcWOhuADG2I",
        "outputId": "b4a09993-56ad-4281-d914-046282c50d37"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+-----------+--------------+------+------------+\n",
            "|EmpID| Name| Department|       Project|Salary|HoursPerWeek|\n",
            "+-----+-----+-----------+--------------+------+------------+\n",
            "|  101| Ravi|Engineering|     AI Engine| 95000|          42|\n",
            "|  102|Sneha|Engineering| Data Platform| 87000|          45|\n",
            "|  105|Divya|Engineering|     AI Engine| 99000|          48|\n",
            "|  109| Neha|Engineering|Security Suite| 91000|          46|\n",
            "+-----+-----+-----------+--------------+------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"SELECT Name, Project FROM global_temp.employees_global WHERE HoursPerWeek > 40\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUaCAkxkDLA9",
        "outputId": "42aec7d0-879b-488f-9a85-1645beee17af"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------+\n",
            "| Name|       Project|\n",
            "+-----+--------------+\n",
            "| Ravi|     AI Engine|\n",
            "|Sneha| Data Platform|\n",
            "|Divya|     AI Engine|\n",
            "|Manav|      Lead Gen|\n",
            "| Neha|Security Suite|\n",
            "+-----+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession, Row\n",
        "\n",
        "# Step 1: Start Spark session\n",
        "spark = SparkSession.builder.appName(\"EmployeeWorkData\").getOrCreate()\n",
        "\n",
        "# Step 2: Prepare the employee data\n",
        "data = [\n",
        "    Row(EmpID=101, Name=\"Ravi\", Department=\"Engineering\", Project=\"AI Engine\", Salary=95000, HoursPerWeek=42),\n",
        "    Row(EmpID=102, Name=\"Sneha\", Department=\"Engineering\", Project=\"Data Platform\", Salary=87000, HoursPerWeek=45),\n",
        "    Row(EmpID=103, Name=\"Kabir\", Department=\"Marketing\", Project=\"Product Launch\", Salary=65000, HoursPerWeek=40),\n",
        "    Row(EmpID=104, Name=\"Anita\", Department=\"Sales\", Project=\"Client Outreach\", Salary=70000, HoursPerWeek=38),\n",
        "    Row(EmpID=105, Name=\"Divya\", Department=\"Engineering\", Project=\"AI Engine\", Salary=99000, HoursPerWeek=48),\n",
        "    Row(EmpID=106, Name=\"Amit\", Department=\"Marketing\", Project=\"Social Media\", Salary=62000, HoursPerWeek=35),\n",
        "    Row(EmpID=107, Name=\"Priya\", Department=\"HR\", Project=\"Policy Revamp\", Salary=58000, HoursPerWeek=37),\n",
        "    Row(EmpID=108, Name=\"Manav\", Department=\"Sales\", Project=\"Lead Gen\", Salary=73000, HoursPerWeek=41),\n",
        "    Row(EmpID=109, Name=\"Neha\", Department=\"Engineering\", Project=\"Security Suite\", Salary=91000, HoursPerWeek=46),\n",
        "    Row(EmpID=110, Name=\"Farah\", Department=\"HR\", Project=\"Onboarding\", Salary=60000, HoursPerWeek=36),\n",
        "]\n",
        "\n",
        "# Step 3: Create DataFrame\n",
        "df = spark.createDataFrame(data)\n",
        "\n",
        "# Step 4: Create local view\n",
        "df.createOrReplaceTempView(\"employees_local\")\n",
        "\n",
        "# Step 5: Run SQL queries\n",
        "print(\" Employees working on 'AI Engine':\")\n",
        "spark.sql(\"SELECT * FROM employees_local WHERE Project = 'AI Engine'\").show()\n",
        "\n",
        "print(\" Marketing employees with salary > 60000:\")\n",
        "spark.sql(\"SELECT * FROM employees_local WHERE Department = 'Marketing' AND Salary > 60000\").show()\n",
        "\n",
        "print(\" Average salary per department:\")\n",
        "spark.sql(\"SELECT Department, ROUND(AVG(Salary), 2) AS Avg_Salary FROM employees_local GROUP BY Department\").show()\n",
        "\n",
        "print(\" Top 3 highest paid employees:\")\n",
        "spark.sql(\"SELECT Name, Salary FROM employees_local ORDER BY Salary DESC LIMIT 3\").show()\n",
        "\n",
        "print(\" Employees working more than 40 hours/week:\")\n",
        "spark.sql(\"SELECT * FROM employees_local WHERE HoursPerWeek > 40\").show()\n",
        "\n",
        "print(\" Employees per project:\")\n",
        "spark.sql(\"SELECT Project, COUNT(*) AS EmployeeCount FROM employees_local GROUP BY Project\").show()\n",
        "\n",
        "# Step 6: Drop the local temp view\n",
        "spark.catalog.dropTempView(\"employees_local\")\n",
        "\n",
        "# Step 7: Try accessing dropped view (will raise AnalysisException)\n",
        "try:\n",
        "    spark.sql(\"SELECT * FROM employees_local\").show()\n",
        "except Exception as e:\n",
        "    print(\" View was dropped. Error:\\n\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OG4GHQQBYjjw",
        "outputId": "3005b9c1-d22c-4b6a-f258-923e9354f918"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Employees working on 'AI Engine':\n",
            "+-----+-----+-----------+---------+------+------------+\n",
            "|EmpID| Name| Department|  Project|Salary|HoursPerWeek|\n",
            "+-----+-----+-----------+---------+------+------------+\n",
            "|  101| Ravi|Engineering|AI Engine| 95000|          42|\n",
            "|  105|Divya|Engineering|AI Engine| 99000|          48|\n",
            "+-----+-----+-----------+---------+------+------------+\n",
            "\n",
            " Marketing employees with salary > 60000:\n",
            "+-----+-----+----------+--------------+------+------------+\n",
            "|EmpID| Name|Department|       Project|Salary|HoursPerWeek|\n",
            "+-----+-----+----------+--------------+------+------------+\n",
            "|  103|Kabir| Marketing|Product Launch| 65000|          40|\n",
            "|  106| Amit| Marketing|  Social Media| 62000|          35|\n",
            "+-----+-----+----------+--------------+------+------------+\n",
            "\n",
            " Average salary per department:\n",
            "+-----------+----------+\n",
            "| Department|Avg_Salary|\n",
            "+-----------+----------+\n",
            "|      Sales|   71500.0|\n",
            "|Engineering|   93000.0|\n",
            "|  Marketing|   63500.0|\n",
            "|         HR|   59000.0|\n",
            "+-----------+----------+\n",
            "\n",
            " Top 3 highest paid employees:\n",
            "+-----+------+\n",
            "| Name|Salary|\n",
            "+-----+------+\n",
            "|Divya| 99000|\n",
            "| Ravi| 95000|\n",
            "| Neha| 91000|\n",
            "+-----+------+\n",
            "\n",
            " Employees working more than 40 hours/week:\n",
            "+-----+-----+-----------+--------------+------+------------+\n",
            "|EmpID| Name| Department|       Project|Salary|HoursPerWeek|\n",
            "+-----+-----+-----------+--------------+------+------------+\n",
            "|  101| Ravi|Engineering|     AI Engine| 95000|          42|\n",
            "|  102|Sneha|Engineering| Data Platform| 87000|          45|\n",
            "|  105|Divya|Engineering|     AI Engine| 99000|          48|\n",
            "|  108|Manav|      Sales|      Lead Gen| 73000|          41|\n",
            "|  109| Neha|Engineering|Security Suite| 91000|          46|\n",
            "+-----+-----+-----------+--------------+------+------------+\n",
            "\n",
            " Employees per project:\n",
            "+---------------+-------------+\n",
            "|        Project|EmployeeCount|\n",
            "+---------------+-------------+\n",
            "|  Data Platform|            1|\n",
            "|      AI Engine|            2|\n",
            "| Product Launch|            1|\n",
            "|Client Outreach|            1|\n",
            "| Security Suite|            1|\n",
            "|  Policy Revamp|            1|\n",
            "|       Lead Gen|            1|\n",
            "|   Social Media|            1|\n",
            "|     Onboarding|            1|\n",
            "+---------------+-------------+\n",
            "\n",
            " View was dropped. Error:\n",
            " [TABLE_OR_VIEW_NOT_FOUND] The table or view `employees_local` cannot be found. Verify the spelling and correctness of the schema and catalog.\n",
            "If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\n",
            "To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 1 pos 14;\n",
            "'Project [*]\n",
            "+- 'UnresolvedRelation [employees_local], [], false\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession, Row\n",
        "from pyspark.sql.functions import avg, col, when\n",
        "\n",
        "# Step 1: Initial Spark session\n",
        "spark = SparkSession.builder.appName(\"GlobalViewExample\").getOrCreate()\n",
        "\n",
        "# Step 2: Create Data\n",
        "data = [\n",
        "    Row(EmpID=101, Name=\"Ravi\", Department=\"Engineering\", Project=\"AI Engine\", Salary=95000, HoursPerWeek=42),\n",
        "    Row(EmpID=102, Name=\"Sneha\", Department=\"Engineering\", Project=\"Data Platform\", Salary=87000, HoursPerWeek=45),\n",
        "    Row(EmpID=103, Name=\"Kabir\", Department=\"Marketing\", Project=\"Product Launch\", Salary=65000, HoursPerWeek=40),\n",
        "    Row(EmpID=104, Name=\"Anita\", Department=\"Sales\", Project=\"Client Outreach\", Salary=70000, HoursPerWeek=38),\n",
        "    Row(EmpID=105, Name=\"Divya\", Department=\"Engineering\", Project=\"AI Engine\", Salary=99000, HoursPerWeek=48),\n",
        "    Row(EmpID=106, Name=\"Amit\", Department=\"Marketing\", Project=\"Social Media\", Salary=62000, HoursPerWeek=35),\n",
        "    Row(EmpID=107, Name=\"Priya\", Department=\"HR\", Project=\"Policy Revamp\", Salary=58000, HoursPerWeek=37),\n",
        "    Row(EmpID=108, Name=\"Manav\", Department=\"Sales\", Project=\"Lead Gen\", Salary=73000, HoursPerWeek=41),\n",
        "    Row(EmpID=109, Name=\"Neha\", Department=\"Engineering\", Project=\"Security Suite\", Salary=91000, HoursPerWeek=46),\n",
        "    Row(EmpID=110, Name=\"Farah\", Department=\"HR\", Project=\"Onboarding\", Salary=60000, HoursPerWeek=36),\n",
        "]\n",
        "\n",
        "# Step 3: Create DataFrame and Global View\n",
        "df = spark.createDataFrame(data)\n",
        "df.createOrReplaceGlobalTempView(\"employees_global\")\n",
        "\n",
        "#  1. HR employees working < 38 hours/week\n",
        "print(\"1. HR employees working < 38 hrs/week:\")\n",
        "spark.sql(\"\"\"\n",
        "    SELECT * FROM global_temp.employees_global\n",
        "    WHERE Department = 'HR' AND HoursPerWeek < 38\n",
        "\"\"\").show()\n",
        "\n",
        "#  2. Total salary payout for each department\n",
        "print(\"2. Total salary per department:\")\n",
        "spark.sql(\"\"\"\n",
        "    SELECT Department, SUM(Salary) AS Total_Salary\n",
        "    FROM global_temp.employees_global\n",
        "    GROUP BY Department\n",
        "\"\"\").show()\n",
        "\n",
        "#  3. Add derived column Status\n",
        "print(\"3. Add Status column (Overworked if >45 hrs):\")\n",
        "df_status = spark.sql(\"SELECT * FROM global_temp.employees_global\") \\\n",
        "    .withColumn(\"Status\", when(col(\"HoursPerWeek\") > 45, \"Overworked\").otherwise(\"Normal\"))\n",
        "df_status.select(\"Name\", \"HoursPerWeek\", \"Status\").show()\n",
        "\n",
        "#  4. Count of employees per project\n",
        "print(\"4. Employee count per project:\")\n",
        "spark.sql(\"\"\"\n",
        "    SELECT Project, COUNT(*) AS Total_Employees\n",
        "    FROM global_temp.employees_global\n",
        "    GROUP BY Project\n",
        "\"\"\").show()\n",
        "\n",
        "#  5. Employees with salary above average in their department\n",
        "print(\"5. Employees with salary above department average:\")\n",
        "dept_avg = df.groupBy(\"Department\").agg(avg(\"Salary\").alias(\"AvgSalary\"))\n",
        "above_avg = df.join(dept_avg, on=\"Department\").filter(col(\"Salary\") > col(\"AvgSalary\"))\n",
        "above_avg.select(\"Name\", \"Department\", \"Salary\", \"AvgSalary\").show()\n",
        "\n",
        "#  6. Open a NEW Spark session and query the global temp view\n",
        "print(\"6. Querying global view from NEW Spark session:\")\n",
        "new_spark = SparkSession.builder.appName(\"NewSession\").getOrCreate()\n",
        "new_spark.sql(\"SELECT Name, Department FROM global_temp.employees_global\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEG0bXe2ZVoj",
        "outputId": "eed94761-f7e8-4100-ab02-910703e79adf"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. HR employees working < 38 hrs/week:\n",
            "+-----+-----+----------+-------------+------+------------+\n",
            "|EmpID| Name|Department|      Project|Salary|HoursPerWeek|\n",
            "+-----+-----+----------+-------------+------+------------+\n",
            "|  107|Priya|        HR|Policy Revamp| 58000|          37|\n",
            "|  110|Farah|        HR|   Onboarding| 60000|          36|\n",
            "+-----+-----+----------+-------------+------+------------+\n",
            "\n",
            "2. Total salary per department:\n",
            "+-----------+------------+\n",
            "| Department|Total_Salary|\n",
            "+-----------+------------+\n",
            "|      Sales|      143000|\n",
            "|Engineering|      372000|\n",
            "|  Marketing|      127000|\n",
            "|         HR|      118000|\n",
            "+-----------+------------+\n",
            "\n",
            "3. Add Status column (Overworked if >45 hrs):\n",
            "+-----+------------+----------+\n",
            "| Name|HoursPerWeek|    Status|\n",
            "+-----+------------+----------+\n",
            "| Ravi|          42|    Normal|\n",
            "|Sneha|          45|    Normal|\n",
            "|Kabir|          40|    Normal|\n",
            "|Anita|          38|    Normal|\n",
            "|Divya|          48|Overworked|\n",
            "| Amit|          35|    Normal|\n",
            "|Priya|          37|    Normal|\n",
            "|Manav|          41|    Normal|\n",
            "| Neha|          46|Overworked|\n",
            "|Farah|          36|    Normal|\n",
            "+-----+------------+----------+\n",
            "\n",
            "4. Employee count per project:\n",
            "+---------------+---------------+\n",
            "|        Project|Total_Employees|\n",
            "+---------------+---------------+\n",
            "|  Data Platform|              1|\n",
            "|      AI Engine|              2|\n",
            "| Product Launch|              1|\n",
            "|Client Outreach|              1|\n",
            "| Security Suite|              1|\n",
            "|  Policy Revamp|              1|\n",
            "|       Lead Gen|              1|\n",
            "|   Social Media|              1|\n",
            "|     Onboarding|              1|\n",
            "+---------------+---------------+\n",
            "\n",
            "5. Employees with salary above department average:\n",
            "+-----+-----------+------+---------+\n",
            "| Name| Department|Salary|AvgSalary|\n",
            "+-----+-----------+------+---------+\n",
            "| Ravi|Engineering| 95000|  93000.0|\n",
            "|Divya|Engineering| 99000|  93000.0|\n",
            "|Kabir|  Marketing| 65000|  63500.0|\n",
            "|Manav|      Sales| 73000|  71500.0|\n",
            "|Farah|         HR| 60000|  59000.0|\n",
            "+-----+-----------+------+---------+\n",
            "\n",
            "6. Querying global view from NEW Spark session:\n",
            "+-----+-----------+\n",
            "| Name| Department|\n",
            "+-----+-----------+\n",
            "| Ravi|Engineering|\n",
            "|Sneha|Engineering|\n",
            "|Kabir|  Marketing|\n",
            "|Anita|      Sales|\n",
            "|Divya|Engineering|\n",
            "| Amit|  Marketing|\n",
            "|Priya|         HR|\n",
            "|Manav|      Sales|\n",
            "| Neha|Engineering|\n",
            "|Farah|         HR|\n",
            "+-----+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession, Row\n",
        "from pyspark.sql.functions import col, row_number\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "# Start Spark session\n",
        "spark = SparkSession.builder.appName(\"BonusChallenges\").getOrCreate()\n",
        "\n",
        "# Sample Data\n",
        "data = [\n",
        "    Row(EmpID=101, Name=\"Ravi\", Department=\"Engineering\", Project=\"AI Engine\", Salary=95000, HoursPerWeek=42),\n",
        "    Row(EmpID=102, Name=\"Sneha\", Department=\"Engineering\", Project=\"Data Platform\", Salary=87000, HoursPerWeek=45),\n",
        "    Row(EmpID=103, Name=\"Kabir\", Department=\"Marketing\", Project=\"Product Launch\", Salary=65000, HoursPerWeek=40),\n",
        "    Row(EmpID=104, Name=\"Anita\", Department=\"Sales\", Project=\"Client Outreach\", Salary=70000, HoursPerWeek=38),\n",
        "    Row(EmpID=105, Name=\"Divya\", Department=\"Engineering\", Project=\"AI Engine\", Salary=99000, HoursPerWeek=48),\n",
        "    Row(EmpID=106, Name=\"Amit\", Department=\"Marketing\", Project=\"Social Media\", Salary=62000, HoursPerWeek=35),\n",
        "    Row(EmpID=107, Name=\"Priya\", Department=\"HR\", Project=\"Policy Revamp\", Salary=58000, HoursPerWeek=37),\n",
        "    Row(EmpID=108, Name=\"Manav\", Department=\"Sales\", Project=\"Lead Gen\", Salary=73000, HoursPerWeek=41),\n",
        "    Row(EmpID=109, Name=\"Neha\", Department=\"Engineering\", Project=\"Security Suite\", Salary=91000, HoursPerWeek=46),\n",
        "    Row(EmpID=110, Name=\"Farah\", Department=\"HR\", Project=\"Onboarding\", Salary=60000, HoursPerWeek=36),\n",
        "]\n",
        "\n",
        "# Create DataFrame\n",
        "df = spark.createDataFrame(data)\n",
        "df.createOrReplaceTempView(\"employees\")\n",
        "\n",
        "# 1. Window function: Rank by salary within department\n",
        "from pyspark.sql.functions import rank\n",
        "window_spec = Window.partitionBy(\"Department\").orderBy(col(\"Salary\").desc())\n",
        "df_ranked = df.withColumn(\"SalaryRank\", rank().over(window_spec))\n",
        "print(\"1. Rank within each department by salary:\")\n",
        "df_ranked.select(\"Name\", \"Department\", \"Salary\", \"SalaryRank\").show()\n",
        "\n",
        "# 2. Create new view for Engineering employees\n",
        "df_engineering = df.filter(col(\"Department\") == \"Engineering\")\n",
        "df_engineering.createOrReplaceGlobalTempView(\"engineering_employees\")\n",
        "print(\"2. Global view 'engineering_employees' created\")\n",
        "\n",
        "# 3. Create view of active employees (working >= 38 hours/week)\n",
        "df_active = df.filter(col(\"HoursPerWeek\") >= 38)\n",
        "df_active.createOrReplaceTempView(\"active_employees\")\n",
        "print(\"3. Temp view 'active_employees' created\")\n",
        "\n",
        "# Optional: Show the active employees\n",
        "spark.sql(\"SELECT * FROM active_employees\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZTqZhuHZxZf",
        "outputId": "84157b4f-f2c8-4685-91d9-1cb64ca94cc3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Rank within each department by salary:\n",
            "+-----+-----------+------+----------+\n",
            "| Name| Department|Salary|SalaryRank|\n",
            "+-----+-----------+------+----------+\n",
            "|Divya|Engineering| 99000|         1|\n",
            "| Ravi|Engineering| 95000|         2|\n",
            "| Neha|Engineering| 91000|         3|\n",
            "|Sneha|Engineering| 87000|         4|\n",
            "|Farah|         HR| 60000|         1|\n",
            "|Priya|         HR| 58000|         2|\n",
            "|Kabir|  Marketing| 65000|         1|\n",
            "| Amit|  Marketing| 62000|         2|\n",
            "|Manav|      Sales| 73000|         1|\n",
            "|Anita|      Sales| 70000|         2|\n",
            "+-----+-----------+------+----------+\n",
            "\n",
            "2. Global view 'engineering_employees' created\n",
            "3. Temp view 'active_employees' created\n",
            "+-----+-----+-----------+---------------+------+------------+\n",
            "|EmpID| Name| Department|        Project|Salary|HoursPerWeek|\n",
            "+-----+-----+-----------+---------------+------+------------+\n",
            "|  101| Ravi|Engineering|      AI Engine| 95000|          42|\n",
            "|  102|Sneha|Engineering|  Data Platform| 87000|          45|\n",
            "|  103|Kabir|  Marketing| Product Launch| 65000|          40|\n",
            "|  104|Anita|      Sales|Client Outreach| 70000|          38|\n",
            "|  105|Divya|Engineering|      AI Engine| 99000|          48|\n",
            "|  108|Manav|      Sales|       Lead Gen| 73000|          41|\n",
            "|  109| Neha|Engineering| Security Suite| 91000|          46|\n",
            "+-----+-----+-----------+---------------+------+------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}